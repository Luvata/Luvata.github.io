<h1 id="cs224n---natural-language-processing-with-deep-learning">CS224N - Natural language processing with Deep Learning</h1>
<ul>
<li>Instructors:
<ul>
<li><a href="Christopher%20manning.md">Christopher manning</a></li>
<li><a href="Abigail%20See.md">Abigail See</a></li>
<li><a href="Richard%20Socher.md">Richard Socher</a></li>
</ul></li>
</ul>
<blockquote>
<p>I completed the second version of this course (2019) last August. Even though this version covers state-of-the-art Deep Learning architecture in NLP, but I found out that the lecture videos of the previous CS224N version is a little better, some early topics that <a href="Richard%20Socher.md">Richard Socher</a> explained are really informative, so I suggests to take a look with the previous version too.</p>
</blockquote>
<h2 id="topic-covers">1. Topic covers</h2>
<h3 id="deep-learning-architectures">1.1 Deep learning architectures</h3>
<ul>
<li>Basic understanding of <a href="DeepLearning.md">DeepLearning</a>, and syntax of <a href="Pytorch.md">Pytorch</a></li>
<li>Beside basic architecture in DL, this course also cover some architectures that are extremely common in NLP:
<ul>
<li><a href="RNN%20family.md">RNN family</a> in Language Model</li>
<li><a href="Convolutional%20Neural%20Network.md">Convolutional Neural Network</a>, and the application of 1D-Conv for represent out-of-vocab words</li>
<li><a href="Seq2Seq%20Architecture.md">Seq2Seq Architecture</a></li>
<li><a href="Attention%20Mechanism.md">Attention Mechanism</a> and <a href="Transformet%20Architecture.md">Transformet Architecture</a></li>
</ul></li>
</ul>
<h3 id="nlp-tasks">1.2 NLP Tasks</h3>
<ul>
<li>Some specific NLP Tasks:
<ul>
<li><a href="Word%20vector%20representation.md">Word vector representation</a>:
<ul>
<li>Static: <a href="Word2Vec.md">Word2Vec</a></li>
<li>Contextualized word embedding: BERT,</li>
</ul></li>
<li><a href="Subword%20representation.md">Subword representation</a></li>
<li><a href="Language%20Model.md">Language Model</a></li>
<li><a href="Dependency%20Parsing.md">Dependency Parsing</a></li>
<li><a href="Machine%20Translation.md">Machine Translation</a></li>
<li><a href="Question%20Answering.md">Question Answering</a></li>
<li><a href="Constituency%20Parsing.md">Constituency Parsing</a></li>
<li><a href="Coreference%20Resolution.md">Coreference Resolution</a></li>
<li><a href="Language%20Generation.md">Language Generation</a></li>
</ul></li>
</ul>
<h3 id="problems-in-nlp">1.3 Problems in NLP</h3>
<ul>
<li>This course also addresses some problems in general of DL and NLP:
<ul>
<li><a href="Fairness%20and%20biases.md">Fairness and biases</a></li>
<li><a href="Low%20resources%20language%20translations.md">Low resources language translations</a></li>
</ul></li>
</ul>
<h2 id="interesting-readings">2. Interesting readings</h2>
